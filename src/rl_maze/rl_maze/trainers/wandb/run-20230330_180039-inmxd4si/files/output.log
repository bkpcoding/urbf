8
1 1 1 1 1 1 1 1 1
1 0 0 0 0 0 0 2 1
1 0 0 0 0 0 0 0 1
1 0 0 0 2 0 0 2 1
1 0 0 2 0 2 0 0 1
1 0 2 0 0 0 0 0 1
1 0 0 0 0 2 0 0 1
1 0 0 0 0 0 0 3 1
1 1 1 1 1 1 1 1 1
[[ 0  0  0  0  0  0  0  0  0]
 [ 0  2  1  2  3  4  5  0  0]
 [ 0  1  2  3  4  5  6  7  0]
 [ 0  2  3  4  0  6  7  0  0]
 [ 0  3  4  0 10  0  8  9  0]
 [ 0  4  0  8  9 10  9 10  0]
 [ 0  5  6  7  8  0 10 11  0]
 [ 0  6  7  8  9 10 11 12  0]
 [ 0  0  0  0  0  0  0  0  0]]
Maze created after 0 tries with 4900 seed
Printing the environment state
[[1 1 1 1 1 1 1 1 1]
 [1 4 0 0 0 0 0 2 1]
 [1 0 0 0 0 0 0 0 1]
 [1 0 0 0 2 0 0 2 1]
 [1 0 0 2 0 2 0 0 1]
 [1 0 2 0 0 0 0 0 1]
 [1 0 0 0 0 2 0 0 1]
 [1 0 0 0 0 0 0 3 1]
 [1 1 1 1 1 1 1 1 1]]
DQNPolicy(
  (q_net): QNetwork(
    (features_extractor): FlattenExtractor(
      (flatten): Flatten(start_dim=1, end_dim=-1)
    )
    (q_net): Sequential(
      (0): MRBF()
      (1): Linear(in_features=128, out_features=32, bias=True)
      (2): ReLU()
      (3): Linear(in_features=32, out_features=128, bias=True)
      (4): ReLU()
      (5): Linear(in_features=128, out_features=4, bias=True)
    )
  )
  (q_net_target): QNetwork(
    (features_extractor): FlattenExtractor(
      (flatten): Flatten(start_dim=1, end_dim=-1)
    )
    (q_net): Sequential(
      (0): MRBF()
      (1): Linear(in_features=128, out_features=32, bias=True)
      (2): ReLU()
      (3): Linear(in_features=32, out_features=128, bias=True)
      (4): ReLU()
      (5): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
reward_per_timestep -3.3
reward_per_timestep -4.1
reward_per_timestep -4.4
reward_per_timestep -4.0
reward_per_timestep -4.4
reward_per_timestep -4.9
reward_per_timestep -4.2
reward_per_timestep -3.7
reward_per_timestep -3.7
reward_per_timestep -4.5
/home/sagar/anaconda3/envs/rbf/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:31: UserWarning: [33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (9, 9)
  logger.warn(
/home/sagar/anaconda3/envs/rbf/lib/python3.8/site-packages/gym/core.py:317: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
/home/sagar/anaconda3/envs/rbf/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
/home/sagar/anaconda3/envs/rbf/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.
  logger.warn(
/home/sagar/anaconda3/envs/rbf/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:190: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.
  logger.warn(
/home/sagar/anaconda3/envs/rbf/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.
  logger.warn(
/home/sagar/anaconda3/envs/rbf/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be uint8, actual type: int64
  logger.warn(
/home/sagar/anaconda3/envs/rbf/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.
  logger.warn(f"{pre} is not within the observation space.")
/home/sagar/anaconda3/envs/rbf/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. 
  logger.deprecation(
/home/sagar/anaconda3/envs/rbf/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: [33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be uint8, actual type: int64
  logger.warn(
/home/sagar/anaconda3/envs/rbf/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: [33mWARN: The obs returned by the `step()` method is not within the observation space.
  logger.warn(f"{pre} is not within the observation space.")
reward_per_timestep -1.2
reward_per_timestep 0.0
reward_per_timestep 0.0
reward_per_timestep 0.0
reward_per_timestep 0.0
reward_per_timestep 0.0
reward_per_timestep 0.0
reward_per_timestep 0.0
reward_per_timestep 0.0
reward_per_timestep 0.0
/media/sagar/73f6012e-728a-4e72-b99f-136fd5461f32/media/sagar/inria/code/stable_baselines3/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
mean_reward:0.00 +/- 0.00
Traceback (most recent call last):
  File "random_trainer2.py", line 81, in <module>
    results = {"0001": (experiment_ids[0], params)}
IndexError: list index out of range