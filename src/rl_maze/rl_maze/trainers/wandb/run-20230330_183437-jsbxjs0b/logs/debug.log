2023-03-30 18:34:37,477 INFO    MainThread:6228 [wandb_setup.py:_flush():76] Configure stats pid to 6228
2023-03-30 18:34:37,477 INFO    MainThread:6228 [wandb_setup.py:_flush():76] Loading settings from /home/sagar/.config/wandb/settings
2023-03-30 18:34:37,477 INFO    MainThread:6228 [wandb_setup.py:_flush():76] Loading settings from /media/sagar/73f6012e-728a-4e72-b99f-136fd5461f32/media/sagar/inria/code/rl_maze/rl_maze/trainers/wandb/settings
2023-03-30 18:34:37,477 INFO    MainThread:6228 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2023-03-30 18:34:37,477 INFO    MainThread:6228 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-03-30 18:34:37,477 INFO    MainThread:6228 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'rl_maze/trainers/random_trainer2.py', 'program': 'random_trainer2.py'}
2023-03-30 18:34:37,477 INFO    MainThread:6228 [wandb_init.py:_log_setup():506] Logging user logs to /media/sagar/73f6012e-728a-4e72-b99f-136fd5461f32/media/sagar/inria/code/rl_maze/rl_maze/trainers/wandb/run-20230330_183437-jsbxjs0b/logs/debug.log
2023-03-30 18:34:37,477 INFO    MainThread:6228 [wandb_init.py:_log_setup():507] Logging internal logs to /media/sagar/73f6012e-728a-4e72-b99f-136fd5461f32/media/sagar/inria/code/rl_maze/rl_maze/trainers/wandb/run-20230330_183437-jsbxjs0b/logs/debug-internal.log
2023-03-30 18:34:37,477 INFO    MainThread:6228 [wandb_init.py:init():546] calling init triggers
2023-03-30 18:34:37,477 INFO    MainThread:6228 [wandb_init.py:init():552] wandb.init called with sweep_config: {}
config: {'size': 9, 'seed': 48, 'difficulty': 1, 'timesteps': 200000.0, 'net_arch': [32, 128], 'lr': 0.001, 'gamma': 0.99, 'batch_size': 64, 'buffer_size': 100000, 'exploration_initial_eps': 1.0, 'exploration_fraction': 0.1, 'exploration_final_eps': 0.02, 'rbf_mlp': False, 'rbf_on': False, 'mrbf_on': True, 'mrbf_units': 128, 'n_neurons_per_input': 10, 'ranges': [0, 10], 'latent_dim': 32, 'sutton_maze': False, 'policy': 'MLP'}
2023-03-30 18:34:37,478 INFO    MainThread:6228 [wandb_init.py:init():602] starting backend
2023-03-30 18:34:37,478 INFO    MainThread:6228 [wandb_init.py:init():606] setting up manager
2023-03-30 18:34:37,481 INFO    MainThread:6228 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-03-30 18:34:37,484 INFO    MainThread:6228 [wandb_init.py:init():613] backend started and connected
2023-03-30 18:34:37,489 INFO    MainThread:6228 [wandb_init.py:init():701] updated telemetry
2023-03-30 18:34:37,509 INFO    MainThread:6228 [wandb_init.py:init():741] communicating run to backend with 60.0 second timeout
2023-03-30 18:34:38,078 INFO    MainThread:6228 [wandb_run.py:_on_init():2133] communicating current version
2023-03-30 18:34:38,717 INFO    MainThread:6228 [wandb_run.py:_on_init():2142] got version response 
2023-03-30 18:34:38,717 INFO    MainThread:6228 [wandb_init.py:init():789] starting run threads in backend
2023-03-30 18:34:44,833 INFO    MainThread:6228 [wandb_run.py:_console_start():2114] atexit reg
2023-03-30 18:34:44,833 INFO    MainThread:6228 [wandb_run.py:_redirect():1969] redirect: SettingsConsole.WRAP_RAW
2023-03-30 18:34:44,833 INFO    MainThread:6228 [wandb_run.py:_redirect():2034] Wrapping output streams.
2023-03-30 18:34:44,833 INFO    MainThread:6228 [wandb_run.py:_redirect():2059] Redirects installed.
2023-03-30 18:34:44,834 INFO    MainThread:6228 [wandb_init.py:init():831] run started, returning control to user process
2023-03-30 18:34:44,886 INFO    MainThread:6228 [wandb_run.py:_config_callback():1251] config_cb None None {'algo': 'DQN', 'policy_class': "<class 'stable_baselines3.dqn.policies.DQNPolicy'>", 'device': 'cpu', 'env': '<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fc67c205dc0>', '_vec_normalize_env': 'None', 'verbose': 1, 'policy_kwargs': '{}', 'observation_space': 'Box(0, 9, (2,), uint8)', 'action_space': 'Discrete(4)', 'n_envs': 1, 'num_timesteps': 0, '_total_timesteps': 200000, '_num_timesteps_at_start': 0, 'eval_env': 'None', 'action_noise': 'None', 'start_time': 1680194084882948165, 'learning_rate': 0.001, 'tensorboard_log': 'None', 'lr_schedule': '<function constant_fn.<locals>.func at 0x7fc67c1a8dc0>', '_last_obs': '[[1 1]]', '_last_episode_starts': '[ True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_logger': '<stable_baselines3.common.logger.Logger object at 0x7fc67c205c10>', '_custom_logger': 'False', 'learning_starts': 10000, 'tau': 1.0, 'gradient_steps': 1, 'optimize_memory_usage': 'False', 'replay_buffer_class': "<class 'stable_baselines3.common.buffers.ReplayBuffer'>", 'replay_buffer_kwargs': '{}', '_episode_storage': 'None', 'config': "AttrDict({'size': 9, 'seed': 4900, 'difficulty': 1, 'timesteps': 200000.0, 'net_arch': [32, 128], 'lr': 0.001, 'gamma': 0.99, 'batch_size': 64, 'buffer_size': 100000, 'exploration_initial_eps': 1.0, 'exploration_fraction': 0.1, 'exploration_final_eps': 0.02, 'rbf_mlp': False, 'rbf_on': False, 'mrbf_on': True, 'mrbf_units': 128, 'n_neurons_per_input': 10, 'ranges': [0, 10], 'latent_dim': 32, 'sutton_maze': False, 'policy': 'MLP'})", 'reward_list': 'deque([], maxlen=1000)', 'train_freq': "TrainFreq(frequency=4, unit=<TrainFrequencyUnit.STEP: 'step'>)", 'actor': 'None', 'replay_buffer': '<stable_baselines3.common.buffers.ReplayBuffer object at 0x7fc67c205e50>', 'use_sde_at_warmup': 'False', 'target_update_interval': 10000, '_n_calls': 0, 'max_grad_norm': 10, 'exploration_rate': 0.0, 'exploration_schedule': '<function get_linear_fn.<locals>.func at 0x7fc67c1a8e50>', 'q_net': 'QNetwork(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (q_net): Sequential(\n    (0): MRBF()\n    (1): Linear(in_features=128, out_features=32, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=32, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=128, out_features=4, bias=True)\n  )\n)', 'q_net_target': 'QNetwork(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (q_net): Sequential(\n    (0): MRBF()\n    (1): Linear(in_features=128, out_features=32, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=32, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=128, out_features=4, bias=True)\n  )\n)', 'torchinfo': 'True'}
2023-03-30 18:35:40,908 WARNING MsgRouterThr:6228 [router.py:message_loop():77] message_loop has been closed
